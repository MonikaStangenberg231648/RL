{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "from sim_class import Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OT2Env(gym.Env):\n",
    "    def __init__(self, render=True, num_agents=1):\n",
    "        super(OT2Env, self).__init__()\n",
    "        \n",
    "        # initializing simulation\n",
    "        self.sim = Simulation(num_agents=num_agents, render=render)\n",
    "        self.workspace_limits = {\n",
    "            \"x\": [-0.26, 0.18],\n",
    "            \"y\": [-0.26, 0.13],\n",
    "            \"z\": [0.08, 0.20]\n",
    "        }\n",
    "\n",
    "        # defining action space\n",
    "        self.action_space = spaces.Box(\n",
    "            low=np.array([-1.0, -1.0, -1.0, 0]), \n",
    "            high=np.array([1.0, 1.0, 1.0, 1]), \n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # defining observation space\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, \n",
    "            high=np.inf, \n",
    "            shape=(6,), \n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        # randomly generating new target position\n",
    "        self.target_position = np.random.uniform(\n",
    "            [self.workspace_limits['x'][0], self.workspace_limits['y'][0], self.workspace_limits['z'][0]],\n",
    "            [self.workspace_limits['x'][1], self.workspace_limits['y'][1], self.workspace_limits['z'][1]]\n",
    "        )\n",
    "\n",
    "        # setting the initial pipette position\n",
    "        self.sim.set_start_position(0.0, 0.0, 0.1)\n",
    "        self.robot_position = np.array([0.0, 0.0, 0.1])\n",
    "\n",
    "        # returning the initial observation \n",
    "        return np.concatenate((self.robot_position, self.target_position))\n",
    "\n",
    "    def step(self, action):\n",
    "        # executing action in the simulation\n",
    "        velocity_x, velocity_y, velocity_z, drop_command = action\n",
    "        self.sim.run(actions=[[velocity_x, velocity_y, velocity_z, drop_command]], num_steps=1)\n",
    "\n",
    "        # getting updated pipette position\n",
    "        states = self.sim.get_states()\n",
    "        pipette_position = states.get(\"robotId_1\", {}).get(\"pipette_position\", [0.0, 0.0, 0.0])\n",
    "\n",
    "        # calculating distance to the target\n",
    "        distance_to_target = np.linalg.norm(np.array(pipette_position) - np.array(self.target_position))\n",
    "\n",
    "        # reward is negative distance\n",
    "        reward = -distance_to_target\n",
    "\n",
    "        # checking if the pipette reached the target\n",
    "        done = distance_to_target < 0.01 \n",
    "\n",
    "        # creating the next observation\n",
    "        observation = np.concatenate((pipette_position, self.target_position))\n",
    "        info = {}\n",
    "\n",
    "        return observation, reward, done, info\n",
    "    \n",
    "    # rendering the environment \n",
    "    def render(self, mode='human'):\n",
    "        if mode == 'human':\n",
    "            pass\n",
    "        elif mode == 'rgb_array':\n",
    "            return self.sim.current_frame\n",
    "        \n",
    "    # closing the simulation\n",
    "    def close(self):\n",
    "        self.sim.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Test the environment with random actions\n",
    "    env = OT2Env(render=True, num_agents=1)\n",
    "\n",
    "    obs = env.reset()\n",
    "    for _ in range(1000):\n",
    "        action = env.action_space.sample()  \n",
    "        obs, reward, done, _ = env.step(action)\n",
    "\n",
    "        if done:\n",
    "            print(\"Target reached!\")\n",
    "            break\n",
    "\n",
    "    env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
